# M2DGRï¼š a Multi-modal and Multi-scenario Dataset for Ground Robots 

## Abstract:

Intelligent ground robots can perform special tasks in complex and dangerous environments and have great application prospects.Positioning and mapping are the key technologies of robot navigation. However, most of the existing data sets of ground robots have limited scenes and few types of sensors, which limits the development of localization algorithms for ground robots in dynamic scenes, night, fog and other challenging environments.In view of this situation, this paper builds a ground robot Gaea and collects a data set M2DGR for robot navigation. The data it provides include Looking around and Skypointing RGB fish-eye camera, depth camera, infrared camera, event camera, inertial measurement unit, laser radar, GNSS receiver.And the positioning accuracy of centimeter-level D-GPS.We collected the sequence with X tracks inside and outside, with a total time of more than XXX hours, including rooms, elevators, streets, parking lots and other scenes.Based on M2DGR, we evaluate the performance of various SLAM algorithms in different scenarios, and analyze the scenarios where SLAM is easy to fail.In order to promote the development and improvement of ground robot navigation algorithms, we make the data set and evaluation results public

keywords:Dataset, Multi-model, Multi-scenario,Ground Robot

## 1.Sensor Setup

## 2.Dataset Sequences
### 2.1 gate3
